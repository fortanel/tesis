{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Manipulación de las imágenes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.pyplot import figure\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de las imagenes\n",
    "data_dir = \"/home/fortanel/Escuela/Tesis/Imagenes/CUADROS-8/\"\n",
    "\n",
    "#Obtiene una lista de los archivos en la ruta proporcionada\n",
    "imagenes = next(os.walk(\"/home/fortanel/Escuela/Tesis/Imagenes/CUADROS-8/\"))[2]\n",
    "print(imagenes[15].replace(\".tif\",\"\"))\n",
    "#Concatenación dedel directorio y el nombre del archivo con el que se desea trabajar\n",
    "fp = os.path.join(data_dir, imagenes[15])\n",
    "\n",
    "#Abrir la imagen\n",
    "raster = rasterio.open(fp)\n",
    "\n",
    "#Se obtiene información de la imagene\n",
    "raster.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imagenes rgb**\n",
    "\n",
    "Las imagenes con las que trabajamos cuentan con 8 bandas. Las bandas 4, 3 y 2 corresponden con los colores rojo, verde y azul respectivamente. Es posible combinar estas bandas para generar una imagen rgb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función read permite obtener los distintas bandas de la imagen, se obtiene un numpy array.\n",
    "red = raster.read(4)\n",
    "green = raster.read(3)\n",
    "blue = raster.read(2)\n",
    "\n",
    "#Normaliza los valores de los arreglos\n",
    "def normalize(array):\n",
    "    \"\"\"Normalizes numpy arrays into scale 0.0 - 1.0\"\"\"\n",
    "    array_min, array_max = array.min(), array.max()\n",
    "    return ((array - array_min)/(array_max - array_min))\n",
    "\n",
    "redn = normalize(red)\n",
    "greenn = normalize(green)\n",
    "bluen = normalize(blue)\n",
    "\n",
    "\n",
    "# Se apilan los arreglos para forma uno solo de dimension 3, el cual puede ser interpretado por \n",
    "#la libreria pyplot como una imagen.\n",
    "rgb = np.dstack((redn,greenn , bluen))\n",
    "\n",
    "#La función figure permite establecer el tamaño y calidad de la imagen al ser mostrada, entre otras opciones\n",
    "figure(num=None, figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\n",
    "#Muestra la imagen\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una función para generar estas imágenes\n",
    "def rgb(dir,landsat):\n",
    "    #Esto es debido a que las imagenes obtenidas del concurso dstl son de un saltelite disinto\n",
    "    if (landsat):\n",
    "        ban = [4,3,2]\n",
    "    else:\n",
    "        ban = [5,3,2]\n",
    "        \n",
    "    imagen = rasterio.open(dir)\n",
    "    red = imagen.read(ban[0])\n",
    "    green = imagen.read(ban[1])\n",
    "    blue = imagen.read(ban[2])\n",
    "\n",
    "    redn = normalize(red)\n",
    "    greenn = normalize(green)\n",
    "    bluen = normalize(blue)\n",
    "\n",
    "    rgb = np.dstack((redn,greenn , bluen))\n",
    "    return rgb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Índice de Vegetación de Diferencia Normalizada**\n",
    "\n",
    "Tambien es posible combinar otras bandas, para obtener nuevos índices como el  Índice de Vegetación de Diferencia Normalizada(NDVI). Recordemos que este indice se calcula de la siguiente manera: $$NDVI= \\frac{IRCercano - Rojo}{IRCercano + Rojo}$$ Donde IRCercano se refiere a la banda correspondientes al infrarrojo cercano y el Rojo a la banda correspondiente al rojo. En el caso de las imágenes con las que trabajamos la banda 5 corresponde al infrarrojo cercano y la 4 a el rojo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos las bandas 5 y 4\n",
    "b4 = raster.read(4)\n",
    "b5 = raster.read(5)\n",
    "\n",
    "#Obtenemos los valores que generan al NDVI\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "ndvi = (b5.astype(float) - b4.astype(float)) / (b5 + b4)\n",
    "\n",
    "#Mostramos la imagen\n",
    "figure(num=None, figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.imshow(ndvi)\n",
    "\n",
    "#Genera una barra que indica los valores correspondeintes a los colores\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la ruta  donde se encuentran las imagenes\n",
    "directorio = \"/home/fortanel/Escuela/Tesis/dstl/imagenes/\"\n",
    "\n",
    "#Definimos el tamaño de las imágenes con las que se trabajaran.\n",
    "tam = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos el nombre de las imagenes con las que se trabajaran\n",
    "ids = next(os.walk(directorio +\"3/\"))[2]\n",
    "ids.remove(\"6010_4_2.tif\")\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion mostramos información sobre las etiquetas y las imagenes con las que se trabajara.\n",
    "Notese que las etiquetas no se encuentran a la misma escala que las imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La etiqueta, se convierte para que solo tenga un color\n",
    "img_to_array(load_img(directorio + \"mascara/\" + ids[18].replace(\".tif\" , \".png\"), grayscale=True)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imagen\n",
    "rasterio.open(directorio + \"16/\" + ids[18].replace(\".tif\" , \"_M.tif\")).meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Comparamos los datos de entrenamiento con sus etiquetas\n",
    "figure(num=None, figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.imshow(rgb( directorio + \"16/\" + ids[18].replace(\".tif\" , \"_M.tif\"),True))\n",
    "\n",
    "#Abrimos las etiquetas, en esta las etiquetas estan en formato png\n",
    "Image.open(directorio + \"mascara/\" + ids[18].replace(\".tif\",\".png\")).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos las variables donde se guardaran las datos de entrenamiento junto a sus etiquetas\n",
    "X = np.zeros((864,tam,tam,8), dtype=np.float32)\n",
    "y = np.zeros((864, tam,tam,1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este paquete tambien permite trabajar con las imágenes en formato tif\n",
    "import tifffile as tiff\n",
    "import cv2\n",
    "\n",
    "#En esta parte del codigo el objetivo es cortar las imágenes con sus respectivas etiquetas en cuadros \n",
    "#de 128x128\n",
    "i = 0\n",
    "for n, id_ in tqdm_notebook(enumerate(ids), total=1):\n",
    "    # Cargamos las imagenes\n",
    "    img = tiff.imread('dstl/imagenes/16/'+ id_.replace(\".tif\",\"_M.tif\") )\n",
    "    \n",
    "    #Cargamos las etiquetas y las convertimos a array\n",
    "    mask = img_to_array(load_img(\"dstl/imagenes/mascara/\" + id_.replace(\".tif\",\".png\"), grayscale=True))\n",
    "    #Esta parte del codigo nos permite reducir el tamaño de las etiquetas para que coincidan con \n",
    "    #las imagenes, manteniendo sus proporciones.\n",
    "    mask = cv2.resize(mask, dsize = (int(len(mask)/4),int(len(mask[0])/4)))\n",
    "    #Omitimos los datos innecesario\n",
    "    mask = mask.reshape(mask.shape[0],mask.shape[1],1)\n",
    "    #mask = zoom(mask, 0.25)\n",
    "    #mask = mask.reshape((len(mask),len(mask[0]) , 1))\n",
    "    j = 0\n",
    "    s = 0\n",
    "    \n",
    "    #Cortamos las imágenes en cuadros de 128*128\n",
    "    while(j < 6):\n",
    "        k = 0\n",
    "        while(k < 6):\n",
    "            aux = img[:,tam*j:tam*(j+1),tam*k:tam*(k+1)]\n",
    "            aux = aux.reshape(tam,tam,8)\n",
    "            # Load masks\n",
    "            aux1 = mask[tam*j:tam*(j+1),tam*k:(tam)*(k+1)]\n",
    "            # Save images\n",
    "            X[36*i + 6*j + k ] = aux/255.0\n",
    "            y[36*i + 6*j + k ] = aux1//255.0\n",
    "            k = k+1 \n",
    "        j = j + 1\n",
    "        \n",
    "    \n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos los datos de entrenamiento y validacion\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "#Se define la red en este caso es U-net.  \n",
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la capata de entrada\n",
    "input_img = Input((tam, tam,8), name='img')\n",
    "\n",
    "#Generamos la red con la que se entrenara\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "\n",
    "#Se configura la red\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "#Esta aprte nos permite configurar el entrenaiento\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-tgs-salt.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Un resumen de la red\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreamos a la red\n",
    "results = model.fit(X_train, y_train, batch_size=32, epochs=3, callbacks=callbacks,\\\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos el desempeño de la red\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los pesos de la mejor red\n",
    "model.load_weights('model-tgs-ds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos el desempeño\n",
    "model.evaluate(X, y,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos una predicción\n",
    "preds_train = model.predict(X, verbose=1)\n",
    "preds_val = model.predict(X, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta parte permite convertir la predicción de los pixeles en 0 y 1.\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizamos el las predicciones\n",
    "resultado = np.zeros((tam*6,tam*6,1), dtype=np.float32)\n",
    "prediccion = np.zeros((tam*6,tam*6,1), dtype=np.float32)\n",
    "v = 0\n",
    "while(v < 6):\n",
    "    w = 0\n",
    "    while(w < 6):\n",
    "        resultado[128*v:128*(v+1), 128*w: 128*(w+1),:] =y[(v*6)+w + 36*13]\n",
    "        prediccion[128*v:128*(v+1), 128*w: 128*(w+1),:] =preds_train_t[(v*6)+w + 36*3]\n",
    "        w = w+1\n",
    "    v = v+1  \n",
    "    \n",
    "tiff.imshow(resultado, cmap = \"gray\")\n",
    "tiff.imshow(prediccion, cmap = \"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
